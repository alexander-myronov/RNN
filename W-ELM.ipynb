{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from twelm import TWELM, XELM, RBFNet, EEM\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "oldsysstdout = sys.stdout\n",
    "class flushfile():\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __getattr__(self,name): \n",
    "        return object.__getattribute__(self.f, name)\n",
    "    def write(self, x):\n",
    "        self.f.write(x)\n",
    "        self.f.flush()\n",
    "    def flush(self):\n",
    "        self.f.flush()\n",
    "sys.stdout = flushfile(sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafiles = [\n",
    "    r'data/5ht2a_ExtFP.libsvm',\n",
    "    r'data/5ht2c_ExtFP.libsvm',\n",
    "    r'data/5ht6_ExtFP.libsvm',\n",
    "    r'data/5ht7_ExtFP.libsvm',\n",
    "    r'data/M1_ExtFP.libsvm',\n",
    "    r'data/SERT_ExtFP.libsvm',\n",
    "    r'data/cathepsin_ExtFP.libsvm',\n",
    "    r'data/d2_ExtFP.libsvm',\n",
    "    r'data/h1_ExtFP.libsvm',\n",
    "    r'data/hERG_ExtFP.libsvm',\n",
    "    r'data/hiv_integrase_ExtFP.libsvm',\n",
    "    r'data/hiv_protease_ExtFP.libsvm',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_cm(confusion_mat, i=0):\n",
    "    # i means which class to choose to do one-vs-the-rest calculation\n",
    "    # rows are actual obs whereas columns are predictions\n",
    "    TP = confusion_mat[i,i]  # correctly labeled as i\n",
    "    FP = confusion_mat[:,i].sum() - TP  # incorrectly labeled as i\n",
    "    FN = confusion_mat[i,:].sum() - TP  # incorrectly labeled as non-i\n",
    "    TN = confusion_mat.sum().sum() - TP - FP - FN\n",
    "    return TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bac_error(Y, Y_predict):\n",
    "    cm = confusion_matrix(Y, Y_predict)\n",
    "    bac_values = np.zeros(cm.shape[0])\n",
    "    for i in xrange(cm.shape[0]):\n",
    "        tp, fp, fn, tn = process_cm(cm, i=i)\n",
    "        if tp+fn > 0 and tn+fp>0:\n",
    "            bac_values[i] = 0.5*tp/(tp+fn) + 0.5*tn/(tn+fp)\n",
    "    return bac_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bac_scorer(estimator, X, Y):\n",
    "    Y_predict = estimator.predict(X)\n",
    "    bac_values = bac_error(Y, Y_predict)\n",
    "    return np.mean(bac_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_grid_search(estimator, features, activity,scorer,param_grid, n_outer_folds, n_inner_folds, n_outer_repetitions):\n",
    "    \"\"\"\n",
    "    returns\n",
    "    test score for each outer fold\n",
    "    best score from grid search\n",
    "    best estimator parameters for each iteration\n",
    "    \"\"\"\n",
    "    test_scores = np.zeros(n_outer_folds*n_outer_repetitions)\n",
    "    train_scores = np.zeros(n_outer_folds*n_outer_repetitions)\n",
    "    best_parameters = []\n",
    "    for rep in range(n_outer_repetitions):\n",
    "        #print('%d/%d' % (rep, n_outer_repetitions))\n",
    "        fold = StratifiedKFold(activity, n_folds=n_outer_folds, shuffle=True)\n",
    "        #print(len(fold))\n",
    "        fit_params = {}\n",
    "        if isinstance(estimator, XELM) and 'h' in param_grid:\n",
    "            max_h = min(features.shape[0], max(param_grid['h']))\n",
    "            fit_params['hidden_layer'] = features[np.random.choice(features.shape[0],\n",
    "                                            max_h,\n",
    "                                            replace=False)]\n",
    "        for i, (train_index, test_index) in enumerate(fold):\n",
    "            search = GridSearchCV(estimator,\\\n",
    "                                  param_grid,\\\n",
    "                                  scoring=scorer,\n",
    "                                  cv=n_inner_folds,\n",
    "                                  n_jobs=1,\n",
    "                                  fit_params=fit_params)\n",
    "\n",
    "            search.fit(features[train_index], activity[train_index])\n",
    "\n",
    "            test_score = scorer(search.best_estimator_, features[test_index], activity[test_index])\n",
    "            test_scores[rep*n_outer_folds+i] = test_score\n",
    "            train_scores[rep*n_outer_folds+i] = search.best_score_\n",
    "\n",
    "            best_parameters.append(search.best_params_)\n",
    "#             print('train score=%f, test score=%f' % (search.best_score_, test_score))\n",
    "            print(search.best_params_)\n",
    "    return test_scores, train_scores, best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_estimator_descritpion(estimator):\n",
    "    name = type(estimator).__name__\n",
    "    if hasattr(estimator, 'metric_name') and not isinstance(estimator, RBFNet):\n",
    "        name+= '(%s)' % estimator.metric_name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_models(estimators, estimator_grids, X, Y, scorer, n_outer_folds, n_inner_folds, n_outer_repetitions):\n",
    "    estimator_scores = []\n",
    "    # estimator_scores_std = np.zeros(len(estimators))\n",
    "    assert len(estimators) == len(estimator_grids)\n",
    "    for i, (estimator, grid) in enumerate(itertools.izip(estimators, estimator_grids)):\n",
    "        print(get_estimator_descritpion(estimator))\n",
    "        \n",
    "        scores_test, _, _ = perform_grid_search(estimator,\n",
    "                                                X,\n",
    "                                                Y,\n",
    "                                                param_grid=grid,\n",
    "                                                scorer=scorer,\n",
    "                                                n_outer_folds=n_outer_folds,\n",
    "                                                n_inner_folds=n_inner_folds, \n",
    "                                                n_outer_repetitions=n_outer_repetitions)\n",
    "        print(scores_test)\n",
    "        estimator_scores.append(scores_test)\n",
    "    \n",
    "    return estimator_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    EEM(h=100, f='tanimoto'),\n",
    "    EEM(h=100, f='kulczynski2'),\n",
    "    EEM(h=100, f='kulczynski3'),\n",
    "    EEM(h=100, f='f1_score'),\n",
    "    RBFNet(h=100),\n",
    "    XELM(h=10, f='tanimoto', balanced=True),\n",
    "    XELM(h=10, f='kulczynski2', balanced=True),\n",
    "    XELM(h=10, f='kulczynski3', balanced=True),\n",
    "    XELM(h=10, f='f1_score', balanced=True),\n",
    "    RandomForestClassifier(n_jobs=-1)\n",
    "]\n",
    "\n",
    "estimator_grids = [\n",
    "    {'C': [ None], 'h': [ 500, 1500]},\n",
    "    {'C': [ None], 'h': [ 500, 1500]},\n",
    "    {'C': [ None], 'h': [ 500, 1500]},\n",
    "    {'C': [ None], 'h': [ 500, 1500]},\n",
    "    {'C': [ 1000, 100000], 'h': [ 500,  1500], 'b':[0.4, 1, 2]},\n",
    "    {'C': [ 1000, 100000], 'h': [ 500,  1500]},\n",
    "    {'C': [ 1000, 100000], 'h': [ 500,  1500]},\n",
    "    {'C': [ 1000, 100000], 'h': [ 500,  1500]},\n",
    "    {'C': [ 1000, 100000], 'h': [ 500,  1500]},\n",
    "    {'n_estimators': [25, 75, 125]}\n",
    "]\n",
    "\n",
    "estimator_grids_simple = [\n",
    "    {'C': [ None], 'h': [ 500]},\n",
    "    {'C': [ None], 'h': [ 500]},\n",
    "    {'C': [ None], 'h': [ 500]},\n",
    "    {'C': [ None], 'h': [ 500]},\n",
    "    {'C': [ 1000], 'h': [   1500], 'b':[0.4,  2]},\n",
    "    {'C': [ 1000], 'h': [   1500]},\n",
    "    {'C': [ 1000], 'h': [   1500]},\n",
    "    {'C': [ 1000], 'h': [   1500]},\n",
    "    {'C': [ 1000], 'h': [   1500]},\n",
    "    {'n_estimators': [75, 125]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def prepare_and_train(datafile):\n",
    "    print(datafile)\n",
    "    features, activity = load_svmlight_file(datafile)    \n",
    "    estimators_scores = test_models(estimators, \n",
    "                                    estimator_grids,\n",
    "                                    features,\n",
    "                                    activity,\n",
    "                                    scorer=bac_scorer,\n",
    "                                    n_outer_folds=3,\n",
    "                                    n_inner_folds=3,\n",
    "                                    n_outer_repetitions=3)\n",
    "    print('%s ready' % datafile)\n",
    "    return datafile, estimator_scores\n",
    "\n",
    "pool = mp.Pool(processes=8)\n",
    "\n",
    "result_series = pool.map(prepare_and_train, datafiles)\n",
    "\n",
    "pool.close()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_grid = pd.DataFrame()\n",
    "scores_grid.loc[:, 'dataset'] = pd.Series()\n",
    "for estimator in estimators:\n",
    "    scores_grid.loc[:,get_estimator_descritpion(estimator) +'_score'] = pd.Series(np.zeros(len(datafiles)))\n",
    "    scores_grid.loc[:, get_estimator_descritpion(estimator)+'_std'] = pd.Series(np.zeros(len(datafiles)))\n",
    "    \n",
    "# scores_values = pd.DataFrame()\n",
    "# scores_values.loc[:, 'dataset'] = pd.Series()\n",
    "# for estimator in estimators:\n",
    "#     scores_values.loc[:, get_estimator_descritpion(estimator)] = pd.Series(index=np.arange(len(datafiles)))\n",
    "\n",
    "scores_values = {}\n",
    "\n",
    "for i, (datafile, estimator_scores) in enumerate(result_series):\n",
    "    print(datafile)\n",
    "    \n",
    "    scores_grid.ix[i, 'dataset'] = datafile\n",
    "    # scores_values.ix[i, 'dataset'] = datafile\n",
    "    \n",
    "    \n",
    "    \n",
    "    for estimator, score in itertools.izip(estimators, estimators_scores):\n",
    "        scores_grid.ix[i, get_estimator_descritpion(estimator)+'_score'] = score.mean()\n",
    "        scores_grid.ix[i, get_estimator_descritpion(estimator)+'_std'] = score.std()\n",
    "        #scores_values.ix[i, get_estimator_descritpion(estimator)] = score\n",
    "        scores_values[(datafile, get_estimator_descritpion(estimator))] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_grid_ds = scores_grid.set_index('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (datafile, estimator_name), scores in scores_values.iteritems():\n",
    "    scores_grid_ds.ix[datafile, (estimator_name+'_stats')] = scipy.stats.shapiro(scores)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_grid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_grid_ds.to_csv(r'data/scores_grid_ds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
